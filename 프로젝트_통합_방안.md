# 프로젝트 통합 방안: Company_Data 통합 프로젝트

## 1. 통합 목표 및 원칙

### 1.1 통합 목표

세 개의 프로젝트(Company_Data, Company_Data_3, Company_Data_5)를 하나의 통합 프로젝트로 병합하여:
- **최고의 아키텍처 채택**: Company_Data_5의 Agent 기반 아키텍처를 기본으로 사용
- **기능 통합**: 각 프로젝트의 우수한 기능들을 통합
- **코드 중복 제거**: 공통 기능을 하나의 모듈로 통합
- **유지보수성 향상**: 단일 코드베이스로 관리 복잡도 감소
- **확장성 확보**: 새로운 기능 추가가 용이한 구조

### 1.2 통합 원칙

1. **Agent 기반 아키텍처 우선**: Company_Data_5의 Agent 기반 구조를 기본 아키텍처로 채택
2. **점진적 통합**: 단계별로 안전하게 통합하여 기존 기능 유지
3. **하위 호환성**: 기존 데이터 및 설정 파일 호환성 유지
4. **최소 침습적**: 기존 동작을 최대한 보존하면서 개선
5. **문서화 우선**: 통합 과정의 모든 변경사항 문서화

---

## 2. 통합 아키텍처 설계

### 2.1 아키텍처 옵션 비교

통합 프로젝트를 위한 세 가지 주요 아키텍처 옵션이 있습니다:

#### 옵션 A: Agent 기반 (Company_Data_5) - Function-calling
#### 옵션 B: LCEL 기반 (LangChain Expression Language) - Runnable 파이프라인
#### 옵션 C: 하이브리드 (LCEL + Agent)

### 2.1.1 옵션 A: Agent 기반 (Company_Data_5)

**특징**:
- Function-calling 기반 표준화된 인터페이스
- 에이전트 레지스트리 시스템으로 자동 관리
- 워크플로우 엔진으로 복잡한 프로세스 처리 가능
- 각 에이전트가 독립적으로 동작

**장점**:
- ✅ 복잡한 의사결정 및 분기 처리에 적합
- ✅ 에이전트 간 명확한 책임 분리
- ✅ 확장 가능한 구조 (새로운 에이전트 추가 용이)
- ✅ Function-calling으로 타입 안정성 확보

**단점**:
- ❌ 상대적으로 복잡한 구조
- ❌ 순차적 파이프라인에는 과도할 수 있음
- ❌ LangChain 생태계와의 직접적 통합 제한적

### 2.1.2 옵션 B: LCEL 기반 (LangChain Expression Language)

**특징**:
- Runnable 인터페이스로 모든 컴포넌트 통일
- 파이프 연산자(`|`)를 사용한 직관적인 체인 구성
- LangChain 생태계와 완벽한 통합
- 스트리밍 및 비동기 지원

**장점**:
- ✅ **직관적인 구문**: 파이프 연산자로 체인 구성이 매우 간결
  ```python
  chain = prompt | llm | parser
  ```
- ✅ **LangChain 생태계 통합**: 모든 LangChain 컴포넌트와 자연스럽게 통합
- ✅ **스트리밍 지원**: 실시간 결과 스트리밍 가능
- ✅ **비동기 지원**: `ainvoke()`로 비동기 실행
- ✅ **병렬 실행**: `RunnableParallel`로 병렬 처리 용이
- ✅ **타입 안정성**: Runnable 인터페이스로 타입 추론 가능
- ✅ **디버깅 용이**: 각 단계별 입력/출력 추적 가능
- ✅ **Company_Data와의 자연스러운 통합**: 기존 Chain 코드를 LCEL로 쉽게 변환

**단점**:
- ❌ 복잡한 분기/반복 로직에는 LangGraph 필요
- ⚠️ Agent와 Tool calling은 지원하지만, LCEL 체인 내에서 직접 사용하려면 Runnable로 래핑 필요

**LCEL 예시 코드**:
```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableParallel, RunnableLambda

# 기본 체인
prompt = ChatPromptTemplate.from_template("기업 {company_name}에 대해 분석해주세요.")
llm = ChatOpenAI(model="gpt-4o-mini")
parser = StrOutputParser()

chain = prompt | llm | parser

# 병렬 실행
parallel_chain = RunnableParallel({
    "basic_info": basic_info_chain,
    "search_results": search_chain,
    "rag_results": rag_chain,
})

# 조건부 분기
def route_input(input_data):
    if input_data.get("use_rag"):
        return rag_chain
    else:
        return web_search_chain

routing_chain = RunnableLambda(route_input) | chain
```

### 2.1.3 옵션 C: 하이브리드 (LCEL + Agent)

**특징**:
- LCEL로 파이프라인 구성, Agent로 복잡한 의사결정 처리
- LCEL 체인을 Agent Tool로 래핑
- Agent를 LCEL 체인 내에서 Runnable로 사용
- **LCEL에서 Agent와 Tool calling 완벽 지원**

**장점**:
- ✅ LCEL의 간결함 + Agent의 유연성
- ✅ 단순한 파이프라인은 LCEL, 복잡한 로직은 Agent
- ✅ Agent와 Tool calling을 LCEL 체인에 직접 통합 가능
- ✅ 최적의 조합

**LCEL에서 Agent 사용 예시**:
```python
from langchain.agents import create_openai_tools_agent, AgentExecutor
from langchain_core.tools import tool
from langchain_core.runnables import RunnableLambda

# Tool 정의
@tool
def search_company(company_name: str) -> str:
    """기업 정보를 검색합니다."""
    return f"{company_name} 정보"

# Agent 생성
agent = create_openai_tools_agent(llm, [search_company], prompt)
agent_executor = AgentExecutor(agent=agent, tools=[search_company])

# LCEL 체인에 Agent 통합 (AgentExecutor는 이미 Runnable)
pipeline = (
    RunnableLambda(prepare_input)
    | agent_executor  # Agent를 직접 사용 (Runnable이므로)
    | process_result
)
```

**구조 예시**:
```python
# LCEL로 파이프라인 구성
pipeline = (
    RunnableLambda(prepare_input)
    | RunnableParallel({
        "basic_info": basic_info_agent_executor,  # AgentExecutor는 Runnable
        "search": search_chain,
    })
    | RunnableLambda(combine_results)
    | insight_agent_executor  # Agent 직접 사용
    | report_chain
)
```

### 2.1.4 아키텍처 선택 권장사항

**추천: 옵션 B (LCEL 기반) 또는 옵션 C (하이브리드)**

**선택 이유**:
1. **Company_Data와의 자연스러운 통합**: 기존 Chain 코드를 LCEL로 쉽게 변환 가능
2. **LangChain 생태계 활용**: RAG, 검색, 파싱 등 모든 LangChain 컴포넌트 활용
3. **간결한 코드**: 파이프 연산자로 복잡한 파이프라인을 간단하게 표현
4. **스트리밍 지원**: 실시간 결과 제공 가능
5. **유연성**: 필요시 Agent를 Runnable로 통합 가능

**하이브리드 접근**:
- 기본 파이프라인: LCEL로 구성 (간결하고 직관적)
- 복잡한 의사결정: Agent 사용 (Tool calling 필요 시)
- **AgentExecutor는 이미 Runnable이므로 LCEL 체인에 직접 사용 가능**
- Tool calling을 포함한 Agent를 LCEL 파이프라인에 자연스럽게 통합

### 2.2 기본 아키텍처: LCEL 기반 (권장)

**선택 이유**:
- LangChain 생태계와 완벽한 통합
- Company_Data의 기존 Chain 코드를 자연스럽게 통합 가능
- 파이프 연산자로 직관적이고 간결한 코드
- 스트리밍 및 비동기 지원
- 필요시 Agent를 Runnable로 통합 가능

### 2.2 통합된 하이브리드 구조 (LCEL + Agent + DI)

**아키텍처 결정**: 하이브리드 방식 + DI 패턴

```
통합 프로젝트/
├── src/
│   ├── chains/                      # LCEL 기반 체인 (기본)
│   │   ├── basic_info/             # 기초 정보 수집 체인
│   │   ├── search/                  # 검색 체인
│   │   │   ├── rag_search_chain.py # RAG 검색 체인
│   │   │   ├── web_search_chain.py # 웹 검색 체인 (DuckDuckGo)
│   │   │   └── tavily_search_chain.py # Tavily 검색 체인
│   │   ├── planner/                 # 검색 전략 계획 체인
│   │   ├── insight/                # 인사이트 생성 체인
│   │   └── report/                  # 보고서 생성 체인
│   ├── agents/                      # Agent (복잡한 로직용, 선택적)
│   │   ├── complex_decision/       # 복잡한 의사결정 Agent
│   │   └── workflow/               # 워크플로우 오케스트레이션 Agent
│   ├── rag/                         # RAG 시스템 (Company_Data_5 기반)
│   │   ├── etl/                     # ETL 파이프라인
│   │   ├── routing/                 # 라우팅 엔진
│   │   └── search/                  # 검색 엔진 (Runnable로 통합)
│   ├── tools/                       # Runnable Tool (LCEL에서 사용)
│   │   ├── dart_tools.py
│   │   ├── search_tools.py
│   │   └── rag_tools.py
│   ├── di/                          # DI 컨테이너 및 설정
│   │   ├── __init__.py
│   │   ├── container.py            # DI 컨테이너 정의
│   │   ├── providers.py             # 의존성 프로바이더
│   │   └── wiring.py                # 의존성 주입 설정
│   ├── modules/                     # 모듈 기반 레거시 지원 (Company_Data_3 호환)
│   │   └── adapters/               # Runnable 어댑터
│   └── shared/                      # 공통 모듈
│       ├── runnables/               # 공통 Runnable 컴포넌트
│       ├── models/                  # 데이터 모델
│       ├── interfaces/              # 인터페이스 정의 (DI용)
│       └── utils/                   # 유틸리티
```

### 2.3 LCEL 기반 통합 전략

#### 2.4.1 LCEL 체인 구성 (기본, DI 적용)
- **Company_Data의 Chain을 LCEL로 자연스럽게 변환**
- 파이프 연산자로 직관적인 파이프라인 구성
- Runnable 인터페이스로 모든 컴포넌트 통일
- **DI를 통해 의존성 주입**

**예시: 5단계 파이프라인을 LCEL로 구성**
```python
from langchain_core.runnables import RunnableParallel, RunnableLambda
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

# 1단계: 기초 정보 수집
basic_info_chain = (
    basic_info_prompt
    | llm
    | basic_info_parser
)

# 2단계: 검색 전략 계획
search_plan_chain = (
    search_plan_prompt
    | llm
    | search_plan_parser
)

# 3단계: 병렬 검색 (RAG + 웹)
search_chain = RunnableParallel({
    "rag_results": rag_retriever | rag_chain,
    "web_results": web_search_tool | web_chain,
})

# 4단계: 인사이트 생성
insight_chain = (
    insight_prompt
    | llm
    | insight_parser
)

# 5단계: 보고서 생성
report_chain = (
    report_prompt
    | llm
    | report_parser
)

# 전체 파이프라인
pipeline = (
    RunnableLambda(prepare_input)
    | basic_info_chain
    | RunnableLambda(save_stage1)
    | search_plan_chain
    | RunnableLambda(save_stage2)
    | search_chain
    | RunnableLambda(save_stage3)
    | insight_chain
    | RunnableLambda(save_stage4)
    | report_chain
    | RunnableLambda(save_final)
)
```

#### 2.3.2 Agent 통합 (필요시)
- **복잡한 의사결정이 필요한 경우에만 Agent 사용**
- Agent를 Runnable로 래핑하여 LCEL 체인에 통합
- Function-calling이 필요한 경우 Agent 활용

**예시: Agent를 LCEL 체인에 통합**
```python
from langchain_core.runnables import RunnableLambda

# Agent를 Runnable로 변환
def agent_as_runnable(agent, input_key="input"):
    def run_agent(data):
        result = agent.invoke(data[input_key])
        return {**data, "agent_result": result}
    return RunnableLambda(run_agent)

# LCEL 체인에 Agent 통합
pipeline = (
    basic_info_chain
    | agent_as_runnable(complex_decision_agent, input_key="basic_info")
    | search_chain
)
```

#### 2.3.3 모듈 호환 레이어 (레거시 지원)
- **Company_Data_3의 모듈을 Runnable로 변환**
- 기존 모듈을 LCEL 체인에서 사용 가능하도록 어댑터 제공

### 2.4 마이그레이션 전략

#### 2.4.1 Company_Data Chain → LCEL 변환

**기존 Chain 코드**:
```python
# Company_Data 방식
chain = LLMChain(llm=llm, prompt=prompt)
result = chain.invoke({"input": data})
```

**LCEL 변환**:
```python
# LCEL 방식
chain = prompt | llm | parser
result = chain.invoke({"input": data})
```

**변환 장점**:
- ✅ 코드가 더 간결하고 읽기 쉬움
- ✅ 스트리밍 지원 (`chain.stream()`)
- ✅ 비동기 지원 (`chain.ainvoke()`)
- ✅ 병렬 실행 용이 (`RunnableParallel`)

#### 2.4.2 Company_Data_5 Agent → LCEL 통합

**Agent를 Runnable로 변환**:
```python
# Agent를 LCEL 체인에서 사용
class AgentRunnable:
    def __init__(self, agent):
        self.agent = agent
    
    def invoke(self, input_data):
        return self.agent.invoke(input_data)
    
    def stream(self, input_data):
        return self.agent.stream(input_data)

# 사용 예시
agent_runnable = AgentRunnable(complex_agent)
chain = prompt | agent_runnable | parser
```

#### 2.4.3 Company_Data_3 모듈 → Runnable 변환

**모듈을 Runnable로 변환**:
```python
from langchain_core.runnables import RunnableLambda

# 모듈을 Runnable로 래핑
def module_as_runnable(module):
    def run_module(data):
        return module.process(data)
    return RunnableLambda(run_module)

# LCEL 체인에 통합
chain = (
    prepare_input
    | module_as_runnable(company_info_module)
    | next_chain
)
```

---

## 3. 기능 통합 계획

### 3.1 검색 엔진 통합

#### 현재 상태
- **Company_Data**: Tavily Search API (유료)
- **Company_Data_3**: DuckDuckGo Search (무료)
- **Company_Data_5**: DuckDuckGo Search (무료)

#### 통합 방안
```
Search Agent - WEB (SAW) 확장
├── 기본: DuckDuckGo Search (무료)
├── 옵션 1: Tavily Search API (유료, 고품질)
└── 옵션 2: 다중 검색 엔진 병렬 실행 후 결과 통합
```

**구현 계획**:
1. SAW를 확장하여 검색 엔진 선택 가능하도록 수정
2. 설정 파일(`config/search_policy.json`)에 검색 엔진 우선순위 정의
3. Tavily Agent를 별도 Agent로 구현하되, SAW와 통합 인터페이스 제공
4. 검색 결과 품질 비교 및 자동 선택 기능 추가

### 3.2 RAG 시스템 통합

#### 현재 상태
- **Company_Data**: 단일 RAG (Slides)
- **Company_Data_3**: 단일 RAG (Slides)
- **Company_Data_5**: 이중 RAG (Notes + Slides, 라우팅 엔진)

#### 통합 방안
```
통합 RAG 시스템 (Company_Data_5 기반)
├── Notes RAG: 노츠 내부 문서 (SPA, MIA용)
├── Slides RAG: 회사소개서 슬라이드 (SAR용)
└── 라우팅 엔진: 메타데이터 기반 자동 분류
```

**구현 계획**:
1. Company_Data_5의 RAG 라우팅 시스템을 기본으로 사용
2. Company_Data와 Company_Data_3의 슬라이드 데이터를 통합
3. ETL 파이프라인으로 자동 분류 및 인덱싱
4. 기존 벡터 저장소 마이그레이션 스크립트 제공

### 3.3 LLM 통합 전략

#### 현재 상태
- **Company_Data**: LangChain Chain
- **Company_Data_3**: LangChain LLM
- **Company_Data_5**: OpenAI 직접 (Function-calling)

#### 통합 방안
```
LLM 통합 레이어 (LCEL 기반)
├── 기본: LangChain LCEL (Runnable 파이프라인)
├── LLM: ChatOpenAI, ChatAnthropic 등 (모두 Runnable)
├── Function-calling: Agent 필요시 사용 (Runnable로 통합)
└── 설정: LLM_PROVIDER 환경변수로 선택 가능
```

**구현 계획**:
1. **기본은 LCEL 사용**: 모든 LLM 호출을 LCEL 체인으로 구성
   ```python
   from langchain_openai import ChatOpenAI
   from langchain_core.prompts import ChatPromptTemplate
   
   llm = ChatOpenAI(model="gpt-4o-mini")
   prompt = ChatPromptTemplate.from_template("...")
   chain = prompt | llm | parser
   ```

2. **Function-calling 필요시**: Agent를 Runnable로 래핑하여 LCEL 체인에 통합
   ```python
   # Function-calling이 필요한 경우
   agent = create_openai_tools_agent(llm, tools, prompt)
   agent_runnable = AgentRunnable(agent)
   chain = prepare_input | agent_runnable | process_result
   ```

3. **프롬프트 관리**: Company_Data의 prompts/ 폴더 구조를 LCEL 체인별로 재구성
   - 각 체인별로 프롬프트 파일 분리
   - ChatPromptTemplate으로 표준화

4. **스트리밍 지원**: LCEL의 기본 기능 활용
   ```python
   for chunk in chain.stream(input_data):
       print(chunk)  # 실시간 결과 출력
   ```

### 3.4 보고서 생성 통합

#### 현재 상태
- **Company_Data**: HTML 보고서 (Jinja2 템플릿)
- **Company_Data_3**: HTML 보고서 (Jinja2 템플릿)
- **Company_Data_5**: HTML 보고서 (Jinja2 템플릿)

#### 통합 방안
```
통합 보고서 생성 시스템
├── 템플릿 통합: 최고의 템플릿 선택 및 개선
├── 단계별 저장 옵션: Company_Data 방식 지원
├── 통합 저장 옵션: Company_Data_3/5 방식 지원
└── 다중 형식 지원: JSON, HTML, PDF (향후)
```

**구현 계획**:
1. 세 프로젝트의 템플릿을 비교하여 최고의 템플릿 선택
2. Company_Data의 단계별 저장 기능을 옵션으로 제공
3. 보고서 생성 Agent(MRA)에 저장 방식 선택 기능 추가
4. 템플릿 커스터마이징 기능 제공

### 3.5 로깅 및 모니터링 통합

#### 현재 상태
- **Company_Data**: 기본 logging + LangSmith
- **Company_Data_3**: Rich Handler
- **Company_Data_5**: Structlog (구조화된 로깅)

#### 통합 방안
```
통합 로깅 시스템
├── 기본: Structlog (구조화된 로깅)
├── 콘솔 출력: Rich Handler (사용자 친화적)
├── 파일 로깅: JSON 형식 (분석 용이)
└── 모니터링: LangSmith 통합 (토큰 추적)
```

**구현 계획**:
1. Structlog를 기본으로 사용하되 Rich Handler로 콘솔 출력
2. LangSmith 통합 유지 (Company_Data의 토큰 추적 기능)
3. 로그 레벨 및 출력 형식 설정 가능
4. 에러 추적 및 성능 모니터링 통합

### 3.6 설정 관리 통합

#### 현재 상태
- **Company_Data**: user.env (환경변수만)
- **Company_Data_3**: env.user + Settings 클래스
- **Company_Data_5**: env.user + ConfigManager + JSON/YAML

#### 통합 방안
```
통합 설정 관리 시스템
├── 환경변수: env.user (기본)
├── 설정 클래스: ConfigManager (Company_Data_5 기반)
├── 정책 파일: config/*.json, *.yaml
└── 검증: Pydantic 스키마
```

**구현 계획**:
1. Company_Data_5의 ConfigManager를 기본으로 사용
2. 모든 환경변수를 env.user로 통합
3. 정책 파일 구조 유지 (rag_routing.json, search_policy.json 등)
4. 설정 검증 및 기본값 제공

---

## 4. 데이터 통합 계획

### 4.1 데이터 소스 통합

```
통합 데이터 구조
data/
├── opendart/                    # DART 데이터 (통합)
│   ├── corpCode.xml
│   └── 한국표준산업분류(11차)표.xlsx
├── slides/                      # 슬라이드 JSON (통합)
│   └── [모든 슬라이드 JSON 파일]
├── company_info/                # 회사소개서 원본 (Company_Data)
│   ├── [노츠]회사소개서.pdf
│   └── [노츠]회사소개서.pptx
└── vector_db/                   # 벡터 데이터베이스
    ├── notes_rag/               # Notes RAG 인덱스
    └── slides_rag/              # Slides RAG 인덱스
```

### 4.2 벡터 저장소 마이그레이션

**마이그레이션 계획**:
1. 기존 벡터 저장소 백업
2. ETL 파이프라인으로 재인덱싱
3. 라우팅 규칙 적용하여 Notes/Slides RAG 분리
4. 마이그레이션 검증 스크립트 실행

### 4.3 결과 파일 통합

```
통합 출력 구조
output/
├── json/                        # JSON 결과
│   ├── 단계별/                  # Company_Data 방식 (옵션)
│   └── 통합/                    # Company_Data_3/5 방식 (기본)
├── html/                        # HTML 보고서
├── logs/                        # 구조화된 로그
└── rag/                         # RAG 관련 출력
```

---

## 5. 코드 통합 전략

### 5.1 통합 우선순위

#### Phase 1: 기반 구조 통합 (1-2주)
1. Company_Data_5의 기본 구조를 통합 프로젝트로 복사
2. 디렉토리 구조 정리 및 통합
3. 설정 관리 시스템 통합
4. 로깅 시스템 통합

#### Phase 2: 핵심 기능 통합 (2-3주)
1. 검색 엔진 통합 (DuckDuckGo + Tavily)
2. RAG 시스템 통합 및 마이그레이션
3. 데이터 소스 통합
4. 기본 Agent 기능 검증

#### Phase 3: 고급 기능 통합 (2-3주)
1. Chain 호환 레이어 구현 (Company_Data)
2. 모듈 호환 레이어 구현 (Company_Data_3)
3. 보고서 생성 통합
4. 단계별 저장 기능 추가

#### Phase 4: 테스트 및 최적화 (1-2주)
1. 통합 테스트 작성
2. 성능 테스트 및 최적화
3. 문서화 완료
4. 마이그레이션 가이드 작성

### 5.2 코드 통합 방법 (LCEL 기반 + DI)

#### 5.2.1 Company_Data Chain → LCEL 변환 (DI 적용)
```python
# 기존 Company_Data Chain
from langchain.chains import LLMChain

old_chain = LLMChain(
    llm=llm,
    prompt=prompt,
    output_parser=parser
)

# LCEL 변환 + DI 적용
from langchain_core.runnables import RunnableLambda
from dependency_injector.wiring import inject, Provide

class BasicInfoChain:
    """기초 정보 수집 체인 (DI 사용)"""
    
    @inject
    def __init__(
        self,
        llm = Provide["llm_provider"],
        prompt = Provide["basic_info_prompt"],
        parser = Provide["basic_info_parser"],
    ):
        self.llm = llm
        self.prompt = prompt
        self.parser = parser
        self._chain = None
    
    @property
    def chain(self):
        """LCEL 체인 생성"""
        if self._chain is None:
            self._chain = self.prompt | self.llm | self.parser
        return self._chain
    
    def invoke(self, data):
        return self.chain.invoke(data)
    
    def stream(self, data):
        return self.chain.stream(data)

# 사용 (DI 컨테이너에서 주입)
@inject
def use_chain(chain: BasicInfoChain = Provide["basic_info_chain"]):
    result = chain.invoke({"input": data})
    return result
```

#### 5.2.2 모듈을 Runnable로 변환 (Company_Data_3)
```python
from langchain_core.runnables import RunnableLambda

# Company_Data_3의 모듈을 Runnable로 변환
def module_as_runnable(module):
    """모듈을 LCEL Runnable로 변환"""
    def process(data):
        return module.process(data)
    return RunnableLambda(process)

# 사용 예시
company_info_runnable = module_as_runnable(company_info_module)
chain = prepare_input | company_info_runnable | next_step
```

#### 5.2.3 기능 통합 예시: 통합 검색 체인 (LCEL)
```python
from langchain_core.runnables import RunnableParallel, RunnableLambda
from langchain_core.tools import Tool

# 검색 도구들
ddgs_tool = Tool.from_function(
    func=duckduckgo_search,
    name="duckduckgo_search",
    description="DuckDuckGo 웹 검색"
)

tavily_tool = Tool.from_function(
    func=tavily_search,
    name="tavily_search",
    description="Tavily 웹 검색 (유료, 고품질)"
)

# 통합 검색 체인 (병렬 실행)
def route_search_engine(data):
    """검색 엔진 자동 선택"""
    engine = data.get("search_engine", "auto")
    if engine == "tavily":
        return tavily_tool
    else:
        return ddgs_tool

unified_search_chain = (
    RunnableLambda(route_search_engine)
    | RunnableLambda(lambda tool: tool.invoke)
)

# 또는 병렬 실행 후 결과 통합
parallel_search_chain = RunnableParallel({
    "ddgs": RunnableLambda(lambda x: ddgs_tool.invoke(x["query"])),
    "tavily": RunnableLambda(lambda x: tavily_tool.invoke(x["query"])),
}) | RunnableLambda(merge_search_results)
```

#### 5.2.4 Agent를 LCEL에 통합 (DI 적용)
```python
from langchain_core.runnables import RunnableLambda
from dependency_injector.wiring import inject, Provide

# Agent를 Runnable로 래핑 (DI 사용)
class BasicInfoAgent:
    """기초 정보 수집 Agent (DI 사용)"""
    
    @inject
    def __init__(
        self,
        llm = Provide["llm_provider"],
        tools = Provide["basic_info_tools"],
        prompt = Provide["basic_info_agent_prompt"],
    ):
        self.llm = llm
        self.tools = tools
        self.prompt = prompt
        self._executor = None
    
    @property
    def executor(self):
        """AgentExecutor 생성"""
        if self._executor is None:
            from langchain.agents import create_openai_tools_agent, AgentExecutor
            agent = create_openai_tools_agent(
                self.llm,
                self.tools,
                self.prompt
            )
            self._executor = AgentExecutor(
                agent=agent,
                tools=self.tools
            )
        return self._executor
    
    def invoke(self, input_data):
        return self.executor.invoke(input_data)
    
    def stream(self, input_data):
        return self.executor.stream(input_data)

# LCEL 체인에 통합 (AgentExecutor는 이미 Runnable)
@inject
def create_pipeline(
    basic_info_agent: BasicInfoAgent = Provide["basic_info_agent"],
    search_chain = Provide["search_chain"],
):
    chain = (
        RunnableLambda(prepare_input)
        | basic_info_agent.executor  # AgentExecutor는 Runnable
        | search_chain
        | process_result
    )
    return chain
```

---

## 6. 의존성 통합

### 6.1 통합된 requirements.txt

```python
# 통합 프로젝트 의존성
# Python 3.11.9

# LLM 및 AI
openai>=1.12.0
langchain>=0.3.27          # 호환 레이어용
langchain-openai>=0.3.32   # 호환 레이어용
langchain-community>=0.3.28

# 벡터 저장소
chromadb>=0.4.22
faiss-cpu>=1.12.0

# 검색 엔진
ddgs>=0.1.0                # DuckDuckGo (기본)
tavily-python>=0.7.10      # Tavily (옵션)

# 데이터 처리
pandas>=2.1.0
openpyxl>=3.1.2
lxml>=4.9.3
beautifulsoup4>=4.13.5

# 웹 및 HTTP
requests>=2.31.0
httpx>=0.26.0

# 로깅 및 모니터링
structlog>=23.2.0          # 구조화된 로깅
rich>=13.7.0               # 콘솔 출력
langsmith>=0.3.45          # 토큰 추적

# 템플릿
jinja2>=3.1.2

# 유틸리티
pydantic>=2.5.0            # 데이터 검증
python-dotenv>=1.0.0       # 환경변수
pyyaml>=6.0.1              # 설정 파일
dependency-injector>=4.41.0 # DI 패턴

# 테스트
pytest>=7.4.4
pytest-asyncio>=0.23.2
pytest-cov>=4.1.0

# 개발 도구
black>=23.12.1
flake8>=7.0.0
mypy>=1.8.0
```

### 6.2 선택적 의존성

- **Tavily**: 유료 검색 API 사용 시에만 필요
- **LangSmith**: 토큰 추적 사용 시에만 필요
- **LangChain**: 호환 레이어 사용 시에만 필요

---

## 7. 설정 파일 통합

### 7.1 통합된 env.user 구조

```bash
# LLM 설정
OPENAI_API_KEY=your_api_key
LLM_MODEL_DEFAULT=gpt-4o-mini
LLM_PROVIDER=openai  # openai, langchain

# 검색 엔진 설정
SEARCH_ENGINE_DEFAULT=ddgs  # ddgs, tavily, auto
TAVILY_API_KEY=your_tavily_key  # 선택적

# DART API
DART_API_KEY=your_dart_key

# RAG 설정
RAG_EMBEDDING_MODEL=text-embedding-3-small
RAG_VECTOR_STORE=chroma  # chroma, faiss

# 로깅 설정
LOG_LEVEL=INFO
LOG_FORMAT=json  # json, rich
LANGSMITH_TRACING=true  # 선택적
LANGSMITH_API_KEY=your_langsmith_key  # 선택적

# 출력 설정
OUTPUT_FORMAT=both  # json, html, both
SAVE_STAGES=true  # Company_Data 방식 단계별 저장
```

### 7.2 통합된 config/ 구조

```
config/
├── rag_routing.json          # RAG 라우팅 규칙 (Company_Data_5)
├── search_policy.json         # 검색 정책 (Company_Data_5)
├── spa_strategy.json          # 전략 설정 (Company_Data_5)
├── logging.yaml               # 로깅 설정 (Company_Data_5)
├── di_config.yaml             # DI 컨테이너 설정 (신규)
└── chain_compatibility.json   # Chain 호환 설정 (신규)
```

### 7.3 DI 설정 파일 (di_config.yaml)

```yaml
# config/di_config.yaml
llm:
  model: "gpt-4o-mini"
  temperature: 0
  provider: "openai"

rag:
  vector_store_path: "data/vector_db"
  embedding_model: "text-embedding-3-small"
  chunk_size: 1000
  chunk_overlap: 200

search:
  engine: "ddgs"  # ddgs, tavily, auto
  max_results: 10
  timeout: 30

tools:
  dart:
    api_key: "${DART_API_KEY}"
    timeout: 30
  tavily:
    api_key: "${TAVILY_API_KEY}"
    enabled: false

agents:
  basic_info:
    max_iterations: 5
    verbose: true
  search:
    max_iterations: 10
    verbose: false

chains:
  basic_info:
    save_intermediate: true
  search:
    parallel: true
```

---

## 8. 마이그레이션 계획

### 8.1 데이터 마이그레이션

#### 8.1.1 벡터 저장소 마이그레이션
```bash
# 마이그레이션 스크립트 실행
python scripts/migrate_vector_store.py \
    --source Company_Data/vector_store \
    --target output/rag/ \
    --routing-config config/rag_routing.json
```

#### 8.1.2 결과 파일 마이그레이션
```bash
# 결과 파일 통합 스크립트
python scripts/migrate_results.py \
    --source-dirs Company_Data/results Company_Data_3/result Company_Data_5/output \
    --target output/
```

### 8.2 코드 마이그레이션

#### 8.2.1 단계별 마이그레이션 가이드

**Step 1: 기반 구조 설정**
1. Company_Data_5를 통합 프로젝트 기본으로 복사
2. 디렉토리 구조 정리
3. 기본 설정 파일 통합

**Step 2: 데이터 통합**
1. 모든 데이터 소스를 `data/`로 통합
2. 벡터 저장소 마이그레이션
3. 설정 파일 통합

**Step 3: 기능 통합**
1. 검색 엔진 통합
2. RAG 시스템 통합
3. 보고서 생성 통합

**Step 4: 호환 레이어 추가**
1. Chain 호환 레이어 구현
2. 모듈 호환 레이어 구현
3. 기존 코드 호환성 테스트

**Step 5: 테스트 및 문서화**
1. 통합 테스트 작성
2. 마이그레이션 가이드 작성
3. 사용자 가이드 업데이트

### 8.3 마이그레이션 검증

#### 검증 체크리스트
- [ ] 모든 기존 기능이 통합 프로젝트에서 동작
- [ ] 데이터 마이그레이션 완료 및 검증
- [ ] 설정 파일 통합 및 검증
- [ ] 테스트 통과
- [ ] 성능 저하 없음
- [ ] 문서화 완료

---

## 9. 통합 후 프로젝트 구조

### 9.1 최종 디렉토리 구조

```
unified_company_data/
├── src/
│   ├── chains/                  # LCEL 기반 체인 (기본)
│   │   ├── basic_info/          # 기초 정보 수집 체인
│   │   │   ├── __init__.py
│   │   │   ├── basic_info_chain.py
│   │   │   └── prompts.py
│   │   ├── search/              # 검색 체인
│   │   │   ├── __init__.py
│   │   │   ├── rag_search_chain.py
│   │   │   ├── web_search_chain.py
│   │   │   ├── tavily_search_chain.py
│   │   │   └── unified_search_chain.py
│   │   ├── planner/             # 검색 전략 계획 체인
│   │   ├── insight/             # 인사이트 생성 체인
│   │   ├── report/              # 보고서 생성 체인
│   │   └── pipeline/            # 전체 파이프라인
│   │       └── main_pipeline.py
│   ├── agents/                  # Agent (복잡한 로직용, 선택적)
│   │   ├── complex_decision/   # 복잡한 의사결정 Agent
│   │   └── workflow/            # 워크플로우 오케스트레이션
│   ├── rag/                     # RAG 시스템 (Company_Data_5 기반)
│   │   ├── etl/                 # ETL 파이프라인
│   │   ├── routing/             # 라우팅 엔진
│   │   └── search/              # 검색 엔진 (Runnable로 통합)
│   ├── tools/                   # Runnable Tool
│   │   ├── dart_tools.py
│   │   ├── search_tools.py
│   │   └── rag_tools.py
│   ├── modules/                 # 모듈 호환 레이어 (Company_Data_3)
│   │   └── adapters/            # Runnable 어댑터
│   ├── shared/                  # 공통 모듈
│   │   ├── runnables/           # 공통 Runnable 컴포넌트
│   │   ├── models/              # 데이터 모델
│   │   └── utils/               # 유틸리티
│   └── config/                  # 설정 관리
│
├── config/                      # 설정 파일
│   ├── rag_routing.json
│   ├── search_policy.json
│   ├── spa_strategy.json
│   └── logging.yaml
│
├── data/                        # 통합 데이터
│   ├── opendart/
│   ├── slides/
│   ├── company_info/
│   └── vector_db/
│
├── output/                      # 통합 출력
│   ├── json/
│   ├── html/
│   ├── logs/
│   └── rag/
│
├── docs/                        # 통합 문서
│   ├── integration_guide.md     # 통합 가이드
│   ├── migration_guide.md       # 마이그레이션 가이드
│   ├── architecture.md          # 아키텍처 문서
│   ├── lcel_guide.md            # LCEL 사용 가이드
│   └── api_reference.md         # API 참조
│
├── scripts/                     # 유틸리티 스크립트
│   ├── migrate_vector_store.py
│   ├── migrate_results.py
│   ├── migrate_to_lcel.py        # LCEL 변환 스크립트
│   └── validate_integration.py
│
├── tests/                       # 통합 테스트
│   ├── unit/
│   ├── integration/
│   └── chains/                   # LCEL 체인 테스트
│
├── main.py                      # 메인 진입점
├── env.user                     # 환경변수
├── env.user.template            # 환경변수 템플릿
├── pyproject.toml               # 프로젝트 설정
├── requirements.txt             # 의존성
└── README.md                    # 통합 README
```

### 9.2 주요 변경사항 요약

1. **아키텍처**: **하이브리드 (LCEL + Agent) + DI 패턴**
   - **LCEL 기반**: 파이프 연산자(`|`)로 직관적인 체인 구성
   - **Agent 통합**: Tool calling이 필요한 경우 Agent 사용
   - **DI 패턴**: dependency-injector로 의존성 관리
   - Runnable 인터페이스로 모든 컴포넌트 통일
   - 스트리밍 및 비동기 지원

2. **DI 패턴 도입**:
   - ✅ 의존성 관리 명확화
   - ✅ 테스트 용이성 향상 (Mock 주입)
   - ✅ 결합도 감소 (인터페이스 기반)
   - ✅ 확장성 및 유지보수성 향상
   - ✅ 설정 중앙화

3. **검색 엔진**: DuckDuckGo 기본, Tavily 옵션 (병렬 실행 지원)

4. **RAG 시스템**: 이중 RAG (Notes + Slides) + 라우팅 (Runnable로 통합)

5. **로깅**: Structlog + Rich + LangSmith

6. **설정 관리**: ConfigManager + JSON/YAML + DI 설정

7. **출력 형식**: 통합 JSON + HTML, 단계별 저장 옵션

8. **LCEL + DI 장점**:
   - ✅ Company_Data의 기존 Chain 코드를 자연스럽게 통합
   - ✅ LangChain 생태계와 완벽한 통합
   - ✅ 간결하고 읽기 쉬운 코드
   - ✅ 스트리밍 및 비동기 기본 지원
   - ✅ 병렬 실행 용이 (`RunnableParallel`)
   - ✅ 의존성 주입으로 테스트 및 확장 용이

---

## 10. 리스크 및 대응 방안

### 10.1 주요 리스크

#### 리스크 1: 기존 기능 호환성 문제
- **확률**: 중간
- **영향**: 높음
- **대응**: 호환 레이어 구현, 단계적 마이그레이션

#### 리스크 2: 데이터 마이그레이션 실패
- **확률**: 낮음
- **영향**: 높음
- **대응**: 백업 필수, 검증 스크립트 제공

#### 리스크 3: 성능 저하
- **확률**: 낮음
- **영향**: 중간
- **대응**: 성능 테스트, 최적화

#### 리스크 4: 문서화 부족
- **확률**: 낮음
- **영향**: 중간
- **대응**: 통합 과정 문서화, 마이그레이션 가이드 작성

### 10.2 완화 전략

1. **단계적 통합**: 한 번에 모든 것을 통합하지 않고 단계별로 진행
2. **백업 필수**: 모든 데이터와 설정 파일 백업
3. **테스트 우선**: 각 단계마다 충분한 테스트
4. **롤백 계획**: 문제 발생 시 이전 상태로 복구 가능하도록 준비

---

## 11. 예상 일정

### 11.1 통합 일정 (총 8-10주)

| Phase | 기간 | 주요 작업 |
|-------|------|-----------|
| Phase 1: 기반 구조 | 1-2주 | 구조 통합, 설정 통합 |
| Phase 2: 핵심 기능 | 2-3주 | 검색, RAG, 데이터 통합 |
| Phase 3: 고급 기능 | 2-3주 | 호환 레이어, 보고서 통합 |
| Phase 4: 테스트 | 1-2주 | 테스트, 문서화, 최적화 |

### 11.2 마일스톤

- **M1 (2주)**: 기반 구조 통합 완료
- **M2 (5주)**: 핵심 기능 통합 완료
- **M3 (8주)**: 모든 기능 통합 완료
- **M4 (10주)**: 테스트 및 문서화 완료, 릴리스 준비

---

## 12. 다음 단계

### 12.1 즉시 시작 가능한 작업

1. **통합 프로젝트 기본 구조 생성**
   - Company_Data_5를 기본으로 복사
   - 디렉토리 구조 정리

2. **설정 파일 통합**
   - env.user 통합
   - config/ 파일 통합

3. **데이터 소스 통합**
   - data/ 폴더 통합
   - 중복 제거

### 12.2 승인 필요 작업

1. **아키텍처 결정**: Agent 기반 아키텍처 채택 승인
2. **검색 엔진 전략**: Tavily 통합 여부 결정
3. **마이그레이션 일정**: 단계별 일정 승인

---

## 13. DI 패턴 상세 가이드

### 13.1 DI 컨테이너 완전 예시

```python
# src/di/container.py
from dependency_injector import containers, providers
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from src.chains.basic_info.basic_info_chain import BasicInfoChain
from src.agents.basic_info.basic_info_agent import BasicInfoAgent
from src.tools.dart_tools import DartTool
from src.rag.search.search_engine import RAGSearchEngine

class Container(containers.DeclarativeContainer):
    """DI 컨테이너"""
    
    # 설정
    config = providers.Configuration()
    
    # LLM 프로바이더
    llm_provider = providers.Factory(
        ChatOpenAI,
        model=config.llm.model,
        temperature=config.llm.temperature,
        api_key=config.llm.api_key,
    )
    
    # 프롬프트
    basic_info_prompt = providers.Singleton(
        ChatPromptTemplate.from_template,
        template="기업 {company_name}의 기본 정보를 수집해주세요.",
    )
    
    # RAG 시스템
    rag_retriever = providers.Singleton(
        RAGSearchEngine,
        vector_store_path=config.rag.vector_store_path,
        embedding_model=config.rag.embedding_model,
    )
    
    # Tools
    dart_tool = providers.Factory(
        DartTool,
        api_key=config.tools.dart.api_key,
    )
    
    # LCEL 체인
    basic_info_chain = providers.Factory(
        BasicInfoChain,
        llm=llm_provider,
        prompt=basic_info_prompt,
    )
    
    # Agent
    basic_info_agent = providers.Factory(
        BasicInfoAgent,
        llm=llm_provider,
        tools=providers.List(
            dart_tool,
        ),
        prompt=basic_info_prompt,
    )
    
    # 파이프라인
    main_pipeline = providers.Factory(
        create_main_pipeline,
        basic_info_chain=basic_info_chain,
        basic_info_agent=basic_info_agent,
    )
```

### 13.2 DI를 사용한 테스트

```python
# tests/unit/test_basic_info_chain.py
from dependency_injector import containers, providers
from unittest.mock import Mock

def test_basic_info_chain():
    # Mock 컨테이너 생성
    container = containers.DynamicContainer()
    
    # Mock 의존성 주입
    container.llm_provider = providers.Factory(Mock)
    container.basic_info_prompt = providers.Singleton(Mock)
    
    # 테스트 대상 생성
    chain = BasicInfoChain(
        llm=container.llm_provider(),
        prompt=container.basic_info_prompt(),
    )
    
    # 테스트 실행
    result = chain.invoke({"company_name": "테스트"})
    assert result is not None
```

### 13.3 DI와 LCEL 통합 예시

```python
# src/chains/pipeline/main_pipeline.py
from dependency_injector.wiring import inject, Provide
from langchain_core.runnables import RunnableParallel, RunnableLambda

class MainPipeline:
    """메인 파이프라인 (DI 사용)"""
    
    @inject
    def __init__(
        self,
        basic_info_chain = Provide["basic_info_chain"],
        basic_info_agent = Provide["basic_info_agent"],
        search_chain = Provide["search_chain"],
        insight_chain = Provide["insight_chain"],
        report_chain = Provide["report_chain"],
    ):
        self.basic_info_chain = basic_info_chain
        self.basic_info_agent = basic_info_agent
        self.search_chain = search_chain
        self.insight_chain = insight_chain
        self.report_chain = report_chain
        self._pipeline = None
    
    @property
    def pipeline(self):
        """LCEL 파이프라인 생성"""
        if self._pipeline is None:
            self._pipeline = (
                RunnableLambda(self._prepare_input)
                | self.basic_info_chain.chain
                | RunnableParallel({
                    "search": self.search_chain.chain,
                    "agent": self.basic_info_agent.executor,
                })
                | self.insight_chain.chain
                | self.report_chain.chain
            )
        return self._pipeline
    
    def invoke(self, company_name: str):
        return self.pipeline.invoke(company_name)
    
    def _prepare_input(self, company_name: str):
        return {"company_name": company_name}
```

### 13.4 DI의 장점 요약

1. **의존성 명시**: 모든 의존성이 명확히 정의됨
2. **테스트 용이**: Mock 객체 주입으로 단위 테스트 용이
3. **결합도 감소**: 인터페이스 기반으로 모듈 간 결합도 감소
4. **확장성**: 새로운 구현체 추가 시 기존 코드 수정 최소화
5. **설정 중앙화**: 의존성 설정을 한 곳에서 관리
6. **생명주기 관리**: Singleton, Factory 등으로 객체 생명주기 관리

---

## 14. LCEL 상세 가이드

### 13.1 LCEL 기본 개념

**LangChain Expression Language (LCEL)**는 LangChain의 최신 방식으로, Runnable 인터페이스를 사용하여 체인을 구성합니다.

#### 핵심 개념
- **Runnable**: 모든 LCEL 컴포넌트는 Runnable 인터페이스를 구현
- **파이프 연산자 (`|`)**: 체인을 직관적으로 구성
- **타입 안정성**: 입력/출력 타입이 명확히 정의됨

### 13.2 LCEL 기본 사용법

#### 13.2.1 기본 체인 구성
```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

# 프롬프트
prompt = ChatPromptTemplate.from_template(
    "기업 {company_name}에 대해 분석해주세요."
)

# LLM
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# 파서
parser = StrOutputParser()

# 체인 구성 (파이프 연산자 사용)
chain = prompt | llm | parser

# 실행
result = chain.invoke({"company_name": "삼성전자"})
```

#### 13.2.2 병렬 실행
```python
from langchain_core.runnables import RunnableParallel

# 여러 체인을 병렬로 실행
parallel_chain = RunnableParallel({
    "basic_info": basic_info_chain,
    "search_results": search_chain,
    "rag_results": rag_chain,
})

# 실행 (모든 체인이 동시에 실행됨)
results = parallel_chain.invoke({"company_name": "삼성전자"})
# 결과: {"basic_info": ..., "search_results": ..., "rag_results": ...}
```

#### 13.2.3 조건부 분기
```python
from langchain_core.runnables import RunnableLambda

def route_input(data):
    """입력에 따라 다른 체인 선택"""
    if data.get("use_rag"):
        return rag_chain
    else:
        return web_search_chain

routing_chain = RunnableLambda(route_input)

# 사용
result = routing_chain.invoke({"use_rag": True, "query": "..."})
```

#### 13.2.4 스트리밍
```python
# 실시간 결과 스트리밍
for chunk in chain.stream({"company_name": "삼성전자"}):
    print(chunk, end="", flush=True)
```

#### 13.2.5 비동기 실행
```python
import asyncio

# 비동기 실행
result = await chain.ainvoke({"company_name": "삼성전자"})

# 비동기 스트리밍
async for chunk in chain.astream({"company_name": "삼성전자"}):
    print(chunk)
```

### 13.3 실제 통합 예시: 5단계 파이프라인

```python
from langchain_core.runnables import (
    RunnableParallel,
    RunnableLambda,
    RunnablePassthrough
)
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
import json

# LLM 및 기본 설정
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
parser = StrOutputParser()

# 1단계: 기초 정보 수집
basic_info_prompt = ChatPromptTemplate.from_template("""
기업 {company_name}의 기본 정보를 수집해주세요.
출력은 JSON 형식으로 제공해주세요.
""")

basic_info_chain = (
    basic_info_prompt
    | llm
    | parser
    | RunnableLambda(lambda x: json.loads(x))
)

# 2단계: 검색 전략 계획
search_plan_prompt = ChatPromptTemplate.from_template("""
기업 정보: {basic_info}
이 기업에 대한 검색 전략을 수립해주세요.
""")

search_plan_chain = (
    search_plan_prompt
    | llm
    | parser
)

# 3단계: 병렬 검색 (RAG + 웹)
def create_rag_chain(retriever):
    rag_prompt = ChatPromptTemplate.from_messages([
        ("system", "다음 컨텍스트를 바탕으로 질문에 답변해주세요."),
        ("human", "컨텍스트: {context}\n\n질문: {question}")
    ])
    
    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)
    
    return (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | rag_prompt
        | llm
        | parser
    )

rag_chain = create_rag_chain(rag_retriever)
web_search_chain = RunnableLambda(web_search_tool.invoke)

search_chain = RunnableParallel({
    "rag": rag_chain,
    "web": web_search_chain,
})

# 4단계: 인사이트 생성
insight_prompt = ChatPromptTemplate.from_template("""
기업 정보: {basic_info}
검색 결과: {search_results}
위 정보를 바탕으로 인사이트를 생성해주세요.
""")

insight_chain = (
    insight_prompt
    | llm
    | parser
)

# 5단계: 보고서 생성
report_prompt = ChatPromptTemplate.from_template("""
기업 정보: {basic_info}
인사이트: {insight}
위 정보를 바탕으로 HTML 보고서를 생성해주세요.
""")

report_chain = (
    report_prompt
    | llm
    | parser
)

# 전체 파이프라인
def save_stage(stage_name):
    """단계별 저장 함수"""
    def save(data):
        filename = f"output/json/{stage_name}_{data.get('company_name')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return data
    return RunnableLambda(save)

pipeline = (
    RunnableLambda(lambda x: {"company_name": x})
    | {
        "basic_info": basic_info_chain,
        "company_name": RunnablePassthrough(),
    }
    | save_stage("stage1")
    | {
        "search_plan": search_plan_chain,
        "basic_info": RunnablePassthrough(),
        "company_name": RunnablePassthrough(),
    }
    | save_stage("stage2")
    | {
        "search_results": search_chain,
        "basic_info": RunnablePassthrough(),
        "company_name": RunnablePassthrough(),
    }
    | save_stage("stage3")
    | {
        "insight": insight_chain,
        "basic_info": RunnablePassthrough(),
        "search_results": RunnablePassthrough(),
        "company_name": RunnablePassthrough(),
    }
    | save_stage("stage4")
    | {
        "report": report_chain,
        "basic_info": RunnablePassthrough(),
        "insight": RunnablePassthrough(),
        "company_name": RunnablePassthrough(),
    }
    | save_stage("final")
)

# 실행
result = pipeline.invoke("삼성전자")
```

### 13.4 Agent와 Tool Calling을 LCEL에서 사용하기

**중요**: LCEL에서 Agent와 Tool calling을 완벽하게 지원합니다!

#### 13.4.1 AgentExecutor는 이미 Runnable

`AgentExecutor`는 이미 `Runnable` 인터페이스를 구현하므로, **별도 래핑 없이 LCEL 체인에 직접 사용 가능**합니다.

```python
from langchain.agents import create_openai_tools_agent, AgentExecutor
from langchain_core.tools import tool
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

# 1. Tool 정의
@tool
def search_company_info(company_name: str) -> str:
    """기업 정보를 검색합니다."""
    # 실제 검색 로직
    return f"{company_name}의 정보"

@tool
def get_dart_info(corp_code: str) -> str:
    """DART에서 기업 공시 정보를 조회합니다."""
    # 실제 DART 조회 로직
    return f"{corp_code}의 공시 정보"

tools = [search_company_info, get_dart_info]

# 2. Agent 생성
prompt = ChatPromptTemplate.from_messages([
    ("system", "당신은 기업 정보 수집 전문가입니다."),
    ("human", "{input}"),
    ("placeholder", "{agent_scratchpad}"),
])

llm = ChatOpenAI(model="gpt-4o-mini")
agent = create_openai_tools_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools)

# 3. LCEL 체인에 직접 사용 (AgentExecutor는 이미 Runnable!)
chain = (
    RunnableLambda(lambda x: {"input": x})
    | agent_executor  # 직접 사용 가능!
    | RunnableLambda(lambda x: x["output"])
)

# 실행
result = chain.invoke("삼성전자 정보를 수집해주세요")
```

#### 13.4.2 Tool Calling이 포함된 Agent 파이프라인

```python
from langchain_core.runnables import RunnableParallel, RunnableLambda

# 여러 Agent를 병렬로 실행
parallel_agents = RunnableParallel({
    "basic_info": basic_info_agent_executor,  # Tool calling 포함
    "search": search_agent_executor,          # Tool calling 포함
    "analysis": analysis_agent_executor,      # Tool calling 포함
})

# LCEL 파이프라인에 통합
pipeline = (
    prepare_input
    | parallel_agents
    | combine_results
    | final_report_chain
)
```

#### 13.4.3 Agent와 일반 LCEL 체인 혼합

```python
# Agent (Tool calling 사용) + 일반 LCEL 체인
pipeline = (
    prepare_input
    | basic_info_agent_executor  # Agent (Tool calling)
    | {
        "rag_results": rag_chain,           # 일반 LCEL 체인
        "web_results": web_search_chain,    # 일반 LCEL 체인
        "basic_info": RunnablePassthrough(), # Agent 결과 전달
    }
    | insight_agent_executor  # Agent (Tool calling)
    | report_chain            # 일반 LCEL 체인
)
```

#### 13.4.4 Tool을 LCEL 체인에서 직접 사용

Tool도 Runnable이므로 LCEL 체인에 직접 사용 가능:

```python
from langchain_core.tools import tool
from langchain_core.runnables import RunnableLambda

@tool
def search_tool(query: str) -> str:
    """검색 도구"""
    return search(query)

# Tool을 LCEL 체인에 직접 사용
chain = (
    RunnableLambda(lambda x: {"query": x})
    | RunnableLambda(lambda x: search_tool.invoke(x["query"]))
    | process_result
)

# 또는 더 간단하게
chain = RunnableLambda(lambda x: search_tool.invoke(x)) | process_result
```

#### 13.4.5 실제 통합 예시: Tool Calling Agent

```python
from langchain.agents import create_openai_tools_agent, AgentExecutor
from langchain_core.tools import tool
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableParallel, RunnableLambda

# Tools 정의
@tool
def corp_code_search(company_name: str) -> dict:
    """기업명으로 고유번호를 검색합니다."""
    # 실제 검색 로직
    return {"corp_code": "123456", "company_name": company_name}

@tool
def dart_basic_info(corp_code: str) -> dict:
    """DART에서 기업 기본 정보를 조회합니다."""
    # 실제 DART 조회 로직
    return {"info": "기업 정보"}

@tool
def rag_search(query: str) -> str:
    """RAG 시스템에서 정보를 검색합니다."""
    # 실제 RAG 검색 로직
    return "RAG 검색 결과"

tools = [corp_code_search, dart_basic_info, rag_search]

# Agent 생성
prompt = ChatPromptTemplate.from_messages([
    ("system", "기업 정보를 수집하는 전문가입니다. 필요한 도구를 사용하세요."),
    ("human", "{input}"),
    ("placeholder", "{agent_scratchpad}"),
])

llm = ChatOpenAI(model="gpt-4o-mini")
agent = create_openai_tools_agent(llm, tools, prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools)

# LCEL 파이프라인 구성
pipeline = (
    RunnableLambda(lambda x: {"input": f"기업 {x}의 정보를 수집해주세요"})
    | agent_executor  # Tool calling Agent 직접 사용
    | RunnableLambda(lambda x: x["output"])
    | save_result
)

# 실행
result = pipeline.invoke("삼성전자")
```

#### 13.4.6 요약

✅ **LCEL에서 Agent와 Tool calling 완벽 지원**
- `AgentExecutor`는 이미 `Runnable`이므로 LCEL 체인에 직접 사용 가능
- Tool도 Runnable이므로 LCEL 체인에 직접 사용 가능
- Agent와 일반 LCEL 체인을 자유롭게 혼합 가능
- Tool calling이 포함된 Agent를 파이프라인에 자연스럽게 통합 가능

**핵심 포인트**:
- AgentExecutor = Runnable (별도 래핑 불필요)
- Tool = Runnable (직접 사용 가능)
- LCEL 파이프라인에서 Agent와 Tool calling을 완전히 활용 가능

### 13.5 LCEL의 장점 요약

1. **간결한 코드**: 파이프 연산자로 직관적인 체인 구성
2. **타입 안정성**: 입력/출력 타입이 명확
3. **스트리밍**: 실시간 결과 제공
4. **비동기 지원**: `ainvoke()`, `astream()` 사용
5. **병렬 실행**: `RunnableParallel`로 성능 최적화
6. **LangChain 통합**: 모든 LangChain 컴포넌트와 자연스럽게 통합
7. **디버깅 용이**: 각 단계별 입력/출력 추적 가능

---

## 14. 참고 자료

### 14.1 관련 문서
- `폴더_분석_결과.md`: 세 프로젝트 상세 분석
- Company_Data_5/docs/: Phase별 설계 문서
- Company_Data/docs/specs/: 요구사항 및 설계 문서

### 14.2 LangChain LCEL 공식 문서
- [LangChain LCEL 공식 문서](https://python.langchain.com/docs/concepts/lcel/)
- [Runnable 인터페이스](https://python.langchain.com/docs/concepts/#runnables)
- [LCEL 예제](https://python.langchain.com/docs/expression_language/)

### 14.3 주요 파일 위치
- **Company_Data**: `src/company_info_collector.py`, `src/llm/chains/`
- **Company_Data_3**: `modules/main_controller.py`, `modules/`
- **Company_Data_5**: `src/agents/`, `src/rag/`, `src/registry/`

---

**작성일**: 2025-01-XX  
**작성자**: AI Assistant  
**버전**: 2.0 (LCEL 기반으로 업데이트)  
**상태**: LCEL 통합 방안 포함

